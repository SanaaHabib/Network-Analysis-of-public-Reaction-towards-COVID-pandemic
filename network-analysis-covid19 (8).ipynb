{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"system(\"sudo apt-get -y install libmagick++-dev\", intern=TRUE)\ninstall.packages(\"magick\", verbose=TRUE)\ninstall.packages(\"RWeka\")","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:19:48.513777Z","iopub.execute_input":"2021-10-30T15:19:48.515826Z","iopub.status.idle":"2021-10-30T15:21:36.530448Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Libraries\nlibrary(readr)        # reads in CSV\nlibrary(ggplot2)      # plot library\nlibrary(tidyverse)    # for data manipulation\nlibrary(gridExtra)    # multiple plots in 1\nlibrary(magick)       # attach dope image for visual\nlibrary(scales)       # show the colors\nlibrary(ggrepel)      # for graph repel (labels)\nlibrary(repr)         # resize graphs\nlibrary(hexbin)       # for hive scatter\nlibrary(naniar)       # to check for missing data\nlibrary(lubridate)    # for date and time\nlibrary(tm)\nlibrary(wordcloud)    # beautiful wordclouds\nlibrary(wordcloud2)\nlibrary(tidytext)     # text preprocessing\nlibrary(textdata)     # text preprocessing\nlibrary(reshape2)\nlibrary(knitr)\nlibrary(grid)\nlibrary(ggraph)\nlibrary(ggsci)\nlibrary(devtools)\nlibrary(circlize)\nlibrary(radarchart)\nlibrary(stringr)\nlibrary(sjmisc)\nlibrary(magick)\nlibrary(htmlwidgets)\nlibrary(VIM)          # missing values visual\nlibrary(colorspace)   # maybe for wordcloud\nlibrary(RWeka)\nlibrary(textmineR)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-30T15:21:36.534258Z","iopub.execute_input":"2021-10-30T15:21:36.561535Z","iopub.status.idle":"2021-10-30T15:21:42.103871Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=7)\n\n# Custom Color Palette\nmy_colors <- c(\"#05A4C0\", \"#85CEDA\", \"#D2A7D8\", \"#A67BC5\", \"#BB1C8B\", \"#8D266E\")\nshow_col(my_colors, labels = F, borders = NA)\n\n\n# Custom Theme Variable\nmy_theme <- theme(plot.background = element_rect(fill = \"grey98\", color = \"grey20\"),\n                  panel.background = element_rect(fill = \"grey98\"),\n                  panel.grid.major = element_line(colour = \"grey87\"),\n                  text = element_text(color = \"grey20\"),\n                  plot.title = element_text(size = 22),\n                  plot.subtitle = element_text(size = 17),\n                  axis.title = element_text(size = 15),\n                  axis.text = element_text(size = 15),\n                  legend.box.background = element_rect(color = \"grey20\", fill = \"grey98\", size = 0.1),\n                  legend.box.margin = margin(t = 3, r = 3, b = 3, l = 3),\n                  legend.title = element_blank(),\n                  legend.text = element_text(size = 15),\n                  strip.text = element_text(size=17))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.106898Z","iopub.execute_input":"2021-10-30T15:21:42.108833Z","iopub.status.idle":"2021-10-30T15:21:42.303848Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#  Importing Lexicons for sentiment Analysis \nA lexicon is a dictionary of words that computes the sentiment of a words by analyzing the \"semantic orientation\" of that word in a text. These codings are made by people, through crowdsorcing, etc.\n\n* Afinn: gives the words a number between [-5, 5], where -5 means that the words is very negative and 5 means that the words is very positive.\n* Bing: gives the words an assignment of positive/negative sentiment\n* NRC: assigns the words one of the 8 primary emotions (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and 2 sentiments (positive and negative)","metadata":{}},{"cell_type":"code","source":"afinn <- read_csv(\"../input/bing-nrc-afinn-lexicons/Afinn.csv\",\n                  col_types = cols(word = col_character(), value = col_double()))\nbing <- read_csv(\"../input/bing-nrc-afinn-lexicons/Bing.csv\",\n                 col_types = cols(word = col_character(), sentiment = col_character()))\nnrc <- read_csv(\"../input/bing-nrc-afinn-lexicons/NRC.csv\",\n                col_types = cols(word = col_character(), sentiment = col_character()))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.306827Z","iopub.execute_input":"2021-10-30T15:21:42.308176Z","iopub.status.idle":"2021-10-30T15:21:42.501806Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# OUR DATA","metadata":{}},{"cell_type":"code","source":"# Data Wrangling and Visualization\nlibrary(glue)\nlibrary(cowplot)\nlibrary(magrittr)\nlibrary(plotly)\nlibrary(tidyverse)\nlibrary(widyr)\n# Date & Time Manipulation.\nlibrary(hms)\nlibrary(lubridate) \n# Text Mining\nlibrary(tidytext)\nlibrary(tm)\nlibrary(wordcloud)\n# Network Analysis\nlibrary(igraph)\n# Network Visualization (D3.js)\nlibrary(networkD3)\n# Set notebook directory.\nMAIN.DIR <- here::here()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.505136Z","iopub.execute_input":"2021-10-30T15:21:42.506692Z","iopub.status.idle":"2021-10-30T15:21:42.797201Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data <- read_csv(\"../input/ourcoviddata/FInalCovidData.csv\");\nshow_col_types = TRUE","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.800394Z","iopub.execute_input":"2021-10-30T15:21:42.801883Z","iopub.status.idle":"2021-10-30T15:21:42.952962Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"spec(data)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.955775Z","iopub.execute_input":"2021-10-30T15:21:42.957083Z","iopub.status.idle":"2021-10-30T15:21:42.972780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"aggr(data)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:42.975588Z","iopub.execute_input":"2021-10-30T15:21:42.976879Z","iopub.status.idle":"2021-10-30T15:21:43.255122Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sum(duplicated(data$comments))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.258357Z","iopub.execute_input":"2021-10-30T15:21:43.259980Z","iopub.status.idle":"2021-10-30T15:21:43.306472Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"distinct(data,comments, .keep_all= TRUE)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.309424Z","iopub.execute_input":"2021-10-30T15:21:43.310931Z","iopub.status.idle":"2021-10-30T15:21:43.395678Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data %>% \n  # We  do not want to display accounts.\n  filter(!str_detect(string = comments, pattern = '@')) %>% \n  head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.398757Z","iopub.execute_input":"2021-10-30T15:21:43.400062Z","iopub.status.idle":"2021-10-30T15:21:43.441956Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Let us see the structure of this tibble","metadata":{}},{"cell_type":"code","source":"data %>% glimpse()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.444746Z","iopub.execute_input":"2021-10-30T15:21:43.446161Z","iopub.status.idle":"2021-10-30T15:21:43.467485Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Time series COVID Tweets Analysis","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=9)\n\ndata %>% \n    select(Date) %>% \n    mutate(date =as.Date(data$Date, \"%m/%d/%Y\")) %>% \n    group_by(date) %>% \n    summarize(n = n(), .groups = \"drop_last\") %>%\n\n    ggplot(aes(x=date, y = n)) + \n    geom_line(size = 1.5, color = my_colors[1]) +\n    coord_cartesian(clip = 'off') +\n    my_theme + theme(axis.title.x = element_blank()) +\n    labs(title = \"Number of Tweets in Time\", subtitle = \"2021\", y = \"Frequency\")","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.470551Z","iopub.execute_input":"2021-10-30T15:21:43.471903Z","iopub.status.idle":"2021-10-30T15:21:43.810426Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#  Text Normalization","metadata":{}},{"cell_type":"markdown","source":"* the punctuation - removePunctuation\n* extra white space - stripWhitespace\n* transforms to lower case - tolower\n* stopwords (common words that should be ignored) - stopwords\n* numbers - removeNumbers","metadata":{}},{"cell_type":"code","source":"clean.data <- data %>% \n  # Remove column.\n  select(-  Date) %>% \n  # Convert to lowercase. \n  mutate(Text = comments %>% str_to_lower) %>% \n  # Remove unwanted characters. \n  mutate(Text= comments %>% str_remove_all(pattern = '\\\\n')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = '&amp')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = 'https://t.co/[a-z,A-Z,0-9]*')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = 'http://t.co/[a-z,A-Z,0-9]*')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = 'https')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = 'http')) %>% \n  # Remove hashtags.\n  mutate(Text = comments %>% str_remove_all(pattern = '#[a-z,A-Z]*')) %>% \n  # Remove accounts.\n  mutate(Text = comments %>% str_remove_all(pattern = '@[a-z,A-Z]*')) %>% \n  # Remove retweets.\n  mutate(Text = comments %>% str_remove_all(pattern = 'rt [a-z,A-Z]*: ')) %>% \n  mutate(Text = comments %>% str_remove(pattern = '(rt)')) %>% \n  mutate(Text = comments %>% str_remove_all(pattern = '\\\\_')) \n\n# Replace accents. \nreplacement.list <- list('á' = 'a', 'é' = 'e', 'í' = 'i', 'ó' = 'o', 'ú' = 'u')\n\nclean.data$Text <-  gsub(\"https\\\\S*\", \"\", clean.data$Text)\nclean.data$Text <-  gsub(\"@\\\\S*\", \"\", clean.data$Text) \nclean.data$Text  <-  gsub(\"amp\", \"\", clean.data$Text) \nclean.data$Text  <-  gsub(\"[\\r\\n]\", \"\", clean.data$Text)\nclean.data$Text  <-  gsub(\"[[:punct:]]\", \"\", clean.data$Text)\nclean.data$Text  <- gsub(\"RT\", \"\", clean.data$Text)\nclean.data$Text <- gsub('[0-9]+', '',clean.data$Text)\n\nclean.data %<>% \n  mutate(Text = chartr(old = names(replacement.list) %>% str_c(collapse = ''), \n                       new = replacement.list %>% str_c(collapse = ''),\n                       x = Text))\n\n\nclean.data %>% head(5)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:43.813772Z","iopub.execute_input":"2021-10-30T15:21:43.815585Z","iopub.status.idle":"2021-10-30T15:21:44.456830Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"corpus <-  Corpus(x = VectorSource(x = clean.data$Text))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:44.459675Z","iopub.execute_input":"2021-10-30T15:21:44.461004Z","iopub.status.idle":"2021-10-30T15:21:44.472743Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data.text <- corpus %>% \n  tm_map(removePunctuation) %>% \n  tm_map(removeNumbers) %>% \n  tm_map(removeWords, stopwords('english')) %>% \n  tm_map(PlainTextDocument) # %>% \n  # We could also use stemming by uncommenting the folowing line. \n  # tm_map(stemDocument, 'english')\n\n# Recover data into original tibble.\nclean.data %<>% mutate(Text = data.text[[1]]$content)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:44.475535Z","iopub.execute_input":"2021-10-30T15:21:44.476842Z","iopub.status.idle":"2021-10-30T15:21:44.770375Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Get Hashtags","metadata":{}},{"cell_type":"code","source":"GetHashtags <- function(tweet) {\n\n  hashtag.vector <- str_extract_all(string = tweet, pattern = '#\\\\S+', simplify = TRUE) %>% \n    as.character()\n  \n  hashtag.string <- NA\n  \n  if (length(hashtag.vector) > 0) {\n    \n    hashtag.string <- hashtag.vector %>% str_c(collapse = ', ')\n    \n  } \n\n  return(hashtag.string)\n}\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:44.773196Z","iopub.execute_input":"2021-10-30T15:21:44.774620Z","iopub.status.idle":"2021-10-30T15:21:44.785767Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"hashtags.df <- tibble(\n  Hashtags = data$comments %>% map_chr(.f = ~ GetHashtags(tweet = .x))\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:44.788594Z","iopub.execute_input":"2021-10-30T15:21:44.790062Z","iopub.status.idle":"2021-10-30T15:21:45.075026Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"hashtags.df %>% head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:45.078064Z","iopub.execute_input":"2021-10-30T15:21:45.079414Z","iopub.status.idle":"2021-10-30T15:21:45.098148Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"clean.data %<>% bind_cols(hashtags.df)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:45.101016Z","iopub.execute_input":"2021-10-30T15:21:45.102360Z","iopub.status.idle":"2021-10-30T15:21:45.113440Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Word Cloud","metadata":{}},{"cell_type":"code","source":"# Remove the shortcut 'q' for 'que'.\nextra.stop.words <- c('q')\n\nstopwords.df <- tibble(\n  word = c(stopwords(kind = 'en'),  \n           extra.stop.words)\n  )\n\nwords.df <- clean.data %>% \n  unnest_tokens(input = Text, output = word) %>%  #split the sentences into words/token\n  anti_join(y = stopwords.df, by = 'word')\n\nword.count <- words.df %>% count(word, sort = TRUE)\n\nword.count %>% head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:45.116355Z","iopub.execute_input":"2021-10-30T15:21:45.117674Z","iopub.status.idle":"2021-10-30T15:21:45.460479Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt <- word.count %>% \n  # Set count threshold. \n  filter(n > 600) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  theme_light() + \n  geom_col(fill = 'pink', alpha = 0.8) +\n  xlab(NULL) +\n  coord_flip() +\n  ggtitle(label = 'Top Word Count')\n\nplt %>% ggplotly()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:45.463679Z","iopub.execute_input":"2021-10-30T15:21:45.465238Z","iopub.status.idle":"2021-10-30T15:21:47.720994Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"wordcloud(\n  words = word.count$word, \n  freq = word.count$n, \n  min.freq = 100,max.words=500, random.order=FALSE, rot.per=0.35,scale=c(5,1),\n  colors = brewer.pal(8, 'Dark2')\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:47.726379Z","iopub.execute_input":"2021-10-30T15:21:47.728470Z","iopub.status.idle":"2021-10-30T15:21:48.955810Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Hashtags","metadata":{}},{"cell_type":"code","source":"hashtags.unnested.df <- clean.data %>% \n  select(Hashtags) %>% \n  unnest_tokens(input = Hashtags, output = hashtag)\n  \nhashtags.unnested.count <- hashtags.unnested.df %>% \n  count(hashtag) %>% \n  drop_na()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:48.959261Z","iopub.execute_input":"2021-10-30T15:21:48.961207Z","iopub.status.idle":"2021-10-30T15:21:49.028817Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"wordcloud(\n  words = str_c('#',hashtags.unnested.count$hashtag), \n  freq = hashtags.unnested.count$n, \n  min.freq = 20, max.words=500, random.order=FALSE, rot.per=0.35,scale=c(5,1),\n  colors=brewer.pal(8, 'Dark2')\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:49.031881Z","iopub.execute_input":"2021-10-30T15:21:49.033183Z","iopub.status.idle":"2021-10-30T15:21:49.512220Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=15)\nunnest_sentiments <- data %>% \n    mutate(text = as.character(data$comments)) %>% \n    unnest_tokens(word, text)\n\n\nunnest_sentiments %>% \n    inner_join(bing, by=\"word\") %>%\n    count(word, sentiment, sort=T) %>% \n    acast(word ~ sentiment, value.var = \"n\", fill=0) %>% \n  \n    # wordcloud\n    comparison.cloud(colors=my_colors[c(5, 1)], max.words = 400, title.size = 2,\n                  scale = c(3,0.5))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:49.515338Z","iopub.execute_input":"2021-10-30T15:21:49.517116Z","iopub.status.idle":"2021-10-30T15:21:52.020528Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=9)\n\n# The plot:\nunnest_sentiments %>% \n    inner_join(nrc, \"word\") %>%\n    filter(!sentiment %in% c(\"positive\", \"negative\")) %>% \n    count(sentiment, sort=T) %>% \n\n    ggplot(aes(x=reorder(sentiment, n), y=n)) +\n    geom_bar(stat=\"identity\", aes(fill=n), show.legend=F) +\n    geom_label(aes(label=format(n, big.mark = \",\")), size=5, fill=\"white\") +\n    labs(x=\"Sentiment\", y=\"Frequency\", title=\"What is the overall mood in Tweets?\") +\n    scale_fill_gradient(low = my_colors[3], high = my_colors[1], guide=\"none\") +\n    coord_flip() + \n    my_theme + theme(axis.text.x = element_blank())","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:52.023807Z","iopub.execute_input":"2021-10-30T15:21:52.025678Z","iopub.status.idle":"2021-10-30T15:21:52.411502Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"1. Trust: good, school, safe, hospital\n1. Fear: pandemic, death, government, sick\n1. Anticipation: time, daily, watch","metadata":{}},{"cell_type":"code","source":"unnest_sentiments %>% \n  inner_join(nrc, \"word\") %>% \n  count(sentiment, word, sort=T) %>%\n  group_by(sentiment) %>% \n  arrange(desc(n)) %>% \n  slice(1:7) %>% \n  \n  # Plot:\n  ggplot(aes(x=reorder(word, n), y=n)) +\n  geom_col(aes(fill=sentiment), show.legend = F) +\n  facet_wrap(~sentiment, scales = \"free_y\", nrow = 2, ncol = 5) +\n  coord_flip() +\n  my_theme + theme(axis.text.x = element_blank()) +\n  labs(x=\"Word\", y=\"Frequency\", title=\"Sentiment split by most frequent words\") +\n  scale_fill_manual(values = c(my_colors, \"#BE82AF\", \"#9D4387\", \"#DEC0D7\",\n                                 \"#40BDC8\", \"#80D3DB\", \"#BFE9ED\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:52.414586Z","iopub.execute_input":"2021-10-30T15:21:52.416584Z","iopub.status.idle":"2021-10-30T15:21:53.325563Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=9)\n\nunnest_sentiments %>% \n  # by word and value count number of occurences\n  inner_join(afinn, \"word\") %>% \n  count(word, value, sort=T) %>% \n  mutate(contribution = n * value,\n         sentiment = ifelse(contribution<=0, \"Negative\", \"Positive\")) %>% #another variable\n  arrange(desc(abs(contribution))) %>% \n  head(20)  %>% \n  \n  # plot\n  ggplot(aes(x=reorder(word, contribution), y=contribution, fill=sentiment)) +\n  geom_col(aes(fill=sentiment), show.legend = F) +\n  labs(x=\"Word\", y=\"Contribution\", title=\"Words with biggest contributions in positive/negative sentiments\") +\n  coord_flip() +\n  scale_fill_manual(values=my_colors[c(3, 2)]) + \n  my_theme","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:53.328562Z","iopub.execute_input":"2021-10-30T15:21:53.330358Z","iopub.status.idle":"2021-10-30T15:21:53.614948Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Network Analysis","metadata":{}},{"cell_type":"code","source":"bi.gram.words <- clean.data %>% \n  unnest_tokens(\n    input = Text, \n    output = bigram, \n    token = 'ngrams', \n    n = 2\n  ) %>% \n  filter(! is.na(bigram))\n\nbi.gram.words %>% \n  select(bigram) %>% \n  head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:53.618081Z","iopub.execute_input":"2021-10-30T15:21:53.620049Z","iopub.status.idle":"2021-10-30T15:21:53.742100Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"bi.gram.words %<>% \n  separate(col = bigram, into = c('word1', 'word2'), sep = ' ') %>% \n  filter(! word1 %in% stopwords.df$word) %>% \n  filter(! word2 %in% stopwords.df$word) %>% \n  filter(! is.na(word1)) %>% \n  filter(! is.na(word2)) ","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:53.745052Z","iopub.execute_input":"2021-10-30T15:21:53.746376Z","iopub.status.idle":"2021-10-30T15:21:55.070435Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"bi.gram.count <- bi.gram.words %>% \n  count(word1, word2, sort = TRUE) %>% \n  # We rename the weight column so that the \n  # associated network gets the weights (see below).\n  rename(weight = n)\n\nbi.gram.count %>% head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.073599Z","iopub.execute_input":"2021-10-30T15:21:55.075131Z","iopub.status.idle":"2021-10-30T15:21:55.553343Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Distinct Item1\nsources <- bi.gram.count %>% \n                distinct(word1) %>% \n                rename(label = word1)\n\n# Distinct item2\ndestinations <- bi.gram.count %>% \n                    distinct(word2) %>% \n                    rename(label = word2)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.556328Z","iopub.execute_input":"2021-10-30T15:21:55.557636Z","iopub.status.idle":"2021-10-30T15:21:55.577056Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"* nodes are the unique words - each word has an identification ID\n* edges are the bigrams, meaning that they show how frequently we find a combination of 2 words (represented by their unique ID)","metadata":{}},{"cell_type":"code","source":"# ----- NODES -----\n# Unique Items + create unique ID\nnodes <- full_join(sources, destinations, by=\"label\") %>% rowid_to_column(\"id\")\nnodes\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.579867Z","iopub.execute_input":"2021-10-30T15:21:55.581167Z","iopub.status.idle":"2021-10-30T15:21:55.629990Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# ----- EDGES -----\n# Adds unique ID of Item 1 to data\nedges <- bi.gram.count %>% \n            left_join(nodes, by = c(\"word1\" = \"label\")) %>% \n            rename(from = id)\n\n# Adds unique ID of Item 2 to data\nedges <- edges %>% \n            left_join(nodes, by = c(\"word2\" = \"label\")) %>% \n            rename(to = id) %>% \n            rename(weight = weight)\n\n# Select only From | To | Weight (frequency)\nedges <- edges %>% select(from, to, weight)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.632827Z","iopub.execute_input":"2021-10-30T15:21:55.634116Z","iopub.status.idle":"2021-10-30T15:21:55.664526Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"nodes %>% head(3)\nedges %>% head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.667280Z","iopub.execute_input":"2021-10-30T15:21:55.668588Z","iopub.status.idle":"2021-10-30T15:21:55.693473Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Export the nodes & edges data - \nwrite.csv(nodes,\"nodes.csv\", row.names = FALSE)\nwrite.csv(edges,\"edges.csv\", row.names = FALSE)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.696257Z","iopub.execute_input":"2021-10-30T15:21:55.697558Z","iopub.status.idle":"2021-10-30T15:21:55.758552Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"Rnetwork <- graph_from_data_frame(d=edges, vertices=nodes, directed=T)\ndeg <- degree(\n  Rnetwork,\n  v = V(Rnetwork),\n  mode = c(\"all\"),\n  loops = TRUE,\n  normalized = FALSE\n)\ndeg\ndegree_distribution(Rnetwork)\nplot(degree_distribution(Rnetwork))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:55.761394Z","iopub.execute_input":"2021-10-30T15:21:55.762794Z","iopub.status.idle":"2021-10-30T15:21:56.064753Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"hist(deg, breaks=1:vcount(Rnetwork)-1, main=\"Histogram of node degree\")\nggplot(mapping = aes(x = deg)) +\n    theme_light() +\n\ngeom_histogram(fill = 'blue', bins = 30)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:56.068020Z","iopub.execute_input":"2021-10-30T15:21:56.069360Z","iopub.status.idle":"2021-10-30T15:21:56.500147Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\ncat(\"Total Edges count :\")\necount(Rnetwork)\ncat(\"Total Nodes count :\")\nvcount(Rnetwork)\ncat(\"Average path Length of a Graph :\")\naverage.path.length(Rnetwork)\ncat(\"Maximum Degree of a Node in a Network :\")\nmax(degree(Rnetwork))\ncat(\"Minimum Degree of a Node in a Network :\")\nmin(degree(Rnetwork))\ncat(\"Eccentricity of a Graph :\")\neccentricity(Rnetwork,vids = V(Rnetwork),mode = c(\"all\",\"Out\",\"In\",\"Total\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:21:56.503286Z","iopub.execute_input":"2021-10-30T15:21:56.504661Z","iopub.status.idle":"2021-10-30T15:22:13.835245Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\nRnetwork.ego.networks = make_ego_graph(graph = Rnetwork, nodes = c(9))\nego9 = Rnetwork.ego.networks[[1]]\n\n# plot(ego9)\n# wc <- cluster_walktrap(ego9)\n# members <- membership(wc)\n# karate_d3 <- igraph_to_networkD3(ego9, group = members)\n#  #Create force directed network plot\n# forceNetwork(Links = karate_d3$links, Nodes = karate_d3$nodes, \n#              Source = 'source', Target = 'target', \n#              NodeID = 'name', Group = 'group',\n#             fontSize = 12,\n#   zoom = TRUE, \n#   opacityNoHover = 1  )\nselegoV <- ego(Rnetwork, order=1, nodes = 9, mode = \"all\", mindist = 0)\n# turn the returned list of igraph.vs objects into a graph\nselegoG <- induced_subgraph(Rnetwork,unlist(selegoV))\n\n# plot the subgraph\nplot(selegoG,vertex.label=V(selegoG)$name)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:22:13.838338Z","iopub.execute_input":"2021-10-30T15:22:13.840226Z","iopub.status.idle":"2021-10-30T15:22:20.690426Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\n# Compute the centrality measures for the biggest connected component from above.\nnode.impo.df <- tibble(\n  word = V(Rnetwork)$label,  \n  degree = strength(graph = Rnetwork),\n  closeness = closeness(graph = Rnetwork), \n  betweenness = betweenness(graph = Rnetwork),\n\n    \n)\n# Degree centrality\nnode.impo.df %>% \n  arrange(- degree) %>%\n  head(10)\ncat(\"Eigen Centrality \")\neigen_centrality(Rnetwork)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:22:20.693602Z","iopub.execute_input":"2021-10-30T15:22:20.695470Z","iopub.status.idle":"2021-10-30T15:23:07.059642Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"threshold <- 150\n\n# For visualization purposes we scale by a global factor. \nScaleWeight <- function(x, lambda) {\n  x / lambda\n}\n\nnetwork <-  bi.gram.count %>%\n  filter(weight > threshold) %>%\n  mutate(weight = ScaleWeight(x = weight, lambda = 2E3)) %>% \n  graph_from_data_frame(directed=T) \n\nRnetwork <- graph_from_data_frame(d=edges, vertices=nodes, directed=T) ","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.062654Z","iopub.execute_input":"2021-10-30T15:23:07.064471Z","iopub.status.idle":"2021-10-30T15:23:07.116448Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"Rnetwork","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.119292Z","iopub.execute_input":"2021-10-30T15:23:07.120576Z","iopub.status.idle":"2021-10-30T15:23:07.149868Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"is.weighted(network)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.152692Z","iopub.execute_input":"2021-10-30T15:23:07.153998Z","iopub.status.idle":"2021-10-30T15:23:07.167353Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Store the degree.\nV(network)$degree <- strength(graph = network)\n\n# Compute the weight shares.\nE(network)$width <- E(network)$weight/max(E(network)$weight)\n\nplot(\n  network, \n  vertex.color = 'lightblue',\n  # Scale node size by degree.\n  vertex.size = 20*V(network)$degree,\n  vertex.label.color = 'black', \n  vertex.label.cex = 1, \n  vertex.label.dist = 1.6,\n  edge.color = 'gray', \n  # Set edge width proportional to the weight relative value.\n  edge.width = 4*E(network)$width ,\n  main = 'Bigram Count Network', \n  sub = glue('Weight Threshold: {threshold}'), \n  alpha = 50\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.170283Z","iopub.execute_input":"2021-10-30T15:23:07.171601Z","iopub.status.idle":"2021-10-30T15:23:07.327966Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Get all connected components.\nclusters(graph = network)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.331482Z","iopub.execute_input":"2021-10-30T15:23:07.333369Z","iopub.status.idle":"2021-10-30T15:23:07.352236Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Select biggest connected component.  \nV(network)$cluster <- clusters(graph = network)$membership\n\ncc.network <- induced_subgraph(\n  graph = network,\n  vids = which(V(network)$cluster == which.max(clusters(graph = network)$csize))\n)\n\ncc.network ","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.355007Z","iopub.execute_input":"2021-10-30T15:23:07.356301Z","iopub.status.idle":"2021-10-30T15:23:07.376500Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Store the degree.\nV(cc.network)$degree <- strength(graph = cc.network)\n\n# Compute the weight shares.\nE(cc.network)$width <- E(cc.network)$weight/max(E(cc.network)$weight)\n\n plot(\n  cc.network, \n  vertex.color = 'lightblue',\n  # Scale node size by degree.\n  vertex.size = 10*V(cc.network)$degree,\n  vertex.label.color = 'black', \n  vertex.label.cex = 1, \n  vertex.label.dist = 1.6,\n  edge.color = 'gray', \n  # Set edge width proportional to the weight relative value.\n  edge.width = 3*E(cc.network)$width ,\n  main = 'Bigram Count Network (Biggest Connected Component)', \n  sub = glue('Weiight Threshold: {threshold}'), \n  alpha = 50\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.379353Z","iopub.execute_input":"2021-10-30T15:23:07.380676Z","iopub.status.idle":"2021-10-30T15:23:07.523250Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Treshold\nthreshold <- 10\n\nnetwork <-  bi.gram.count %>%\n  filter(weight > threshold) %>%\n  graph_from_data_frame(directed = FALSE)\n# network <- graph_from_data_frame(d=edges, vertices=nodes, directed=T)\n# Store the degree.\nV(network)$degree <- strength(graph = network)\n# Compute the weight shares.\nE(network)$width <- E(network)$weight/max(E(network)$weight)\n\n# Create networkD3 object.\nnetwork.D3 <- igraph_to_networkD3(g = network)\n# Define node size.\nnetwork.D3$nodes %<>% mutate(Degree = (1E-2)*V(network)$degree)\n# Degine color group (I will explore this feature later).\nnetwork.D3$nodes %<>% mutate(Group = 1)\n# Define edges width. \nnetwork.D3$links$Width <- 10*E(network)$width\n\nforceNetwork(\n  Links = network.D3$links, \n  Nodes = network.D3$nodes, \n  Source = 'source', \n  Target = 'target',\n  NodeID = 'name',\n  Group = 'Group', \n  opacity = 0.9,\n  Value = 'Width',\n  Nodesize = 'Degree', \n  # We input a JavaScript function.\n  linkWidth = JS(\"function(d) { return Math.sqrt(d.value); }\"), \n  fontSize = 12,\n  zoom = TRUE, \n  opacityNoHover = 1\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:07.526254Z","iopub.execute_input":"2021-10-30T15:23:07.528085Z","iopub.status.idle":"2021-10-30T15:23:08.009486Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"#  Community Detection","metadata":{}},{"cell_type":"code","source":"threshold <- 80\n\n# For visualization purposes we scale by a global factor. \nScaleWeight <- function(x, lambda) {\n  x / lambda\n}\n\nRnetwork <-  bi.gram.count %>%\n  filter(weight > threshold) %>%\n  mutate(weight = ScaleWeight(x = weight, lambda = 2E3)) %>% \n  graph_from_data_frame(directed=T) ","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:08.012640Z","iopub.execute_input":"2021-10-30T15:23:08.014355Z","iopub.status.idle":"2021-10-30T15:23:08.037245Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Community Building using Edge Betweeness","metadata":{}},{"cell_type":"code","source":"ceb <- cluster_edge_betweenness(network)\ndendPlot(ceb, mode=\"hclust\")\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:08.040066Z","iopub.execute_input":"2021-10-30T15:23:08.041293Z","iopub.status.idle":"2021-10-30T15:23:18.922485Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"plot(ceb, network)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:18.925828Z","iopub.execute_input":"2021-10-30T15:23:18.927855Z","iopub.status.idle":"2021-10-30T15:23:20.560784Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"class(ceb)\nmembership(ceb)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.563771Z","iopub.execute_input":"2021-10-30T15:23:20.565696Z","iopub.status.idle":"2021-10-30T15:23:20.596425Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# cfg <- cluster_fast_greedy(as.undirected(network))\n# plot(cfg, as.undirected(network))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.599370Z","iopub.execute_input":"2021-10-30T15:23:20.600691Z","iopub.status.idle":"2021-10-30T15:23:20.610076Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# V(network)$community <- cfg$membership\n# colrs <- adjustcolor( c(\"gray50\", \"tomato\", \"gold\", \"yellowgreen\"), alpha=.6)\n# plot(network, vertex.color=colrs[V(network)$community])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.612881Z","iopub.execute_input":"2021-10-30T15:23:20.614222Z","iopub.status.idle":"2021-10-30T15:23:20.623459Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Community Detection Using Skip Gram","metadata":{}},{"cell_type":"code","source":"skip.window <- 2\n\nskip.gram.words <- clean.data %>% \n  unnest_tokens(\n    input = Text, \n    output = skipgram, \n    token = 'skip_ngrams', \n    n = skip.window\n  ) %>% \n  filter(! is.na(skipgram))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.626213Z","iopub.execute_input":"2021-10-30T15:23:20.627571Z","iopub.status.idle":"2021-10-30T15:23:20.950156Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":" clean.data %>% \n  slice(4) %>% \n  pull(Text)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.953417Z","iopub.execute_input":"2021-10-30T15:23:20.954919Z","iopub.status.idle":"2021-10-30T15:23:20.971403Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"skip.gram.words %>% \n  select(skipgram) %>% \n  slice(10:20)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:20.974315Z","iopub.execute_input":"2021-10-30T15:23:20.975652Z","iopub.status.idle":"2021-10-30T15:23:20.998251Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"skip.gram.words$num_words <- skip.gram.words$skipgram %>% \n  map_int(.f = ~ ngram::wordcount(.x))\n\nskip.gram.words %<>% filter(num_words == 2) %>% select(- num_words)\n\nskip.gram.words %<>% \n  separate(col = skipgram, into = c('word1', 'word2'), sep = ' ') %>% \n  filter(! word1 %in% stopwords.df$word) %>% \n  filter(! word2 %in% stopwords.df$word) %>% \n  filter(! is.na(word1)) %>% \n  filter(! is.na(word2)) \n\nskip.gram.count <- skip.gram.words  %>% \n  count(word1, word2, sort = TRUE) %>% \n  rename(weight = n)\n\nskip.gram.count %>% head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:21.001145Z","iopub.execute_input":"2021-10-30T15:23:21.002528Z","iopub.status.idle":"2021-10-30T15:23:28.163126Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Treshold\nthreshold <- 20\n\nnetwork <-  skip.gram.count %>%\n  filter(weight > threshold) %>%\n  graph_from_data_frame(directed = FALSE)\n\n# Select biggest connected component.  \nV(network)$cluster <- clusters(graph = network)$membership\n\ncc.network <- induced_subgraph(\n  graph = network,\n  vids = which(V(network)$cluster == which.max(clusters(graph = network)$csize))\n)\n\n# Store the degree.\nV(cc.network)$degree <- strength(graph = cc.network)\n# Compute the weight shares.\nE(cc.network)$width <- E(cc.network)$weight/max(E(cc.network)$weight)\n\n# Create networkD3 object.\nnetwork.D3 <- igraph_to_networkD3(g = cc.network)\n# Define node size.\nnetwork.D3$nodes %<>% mutate(Degree = (1E-2)*V(cc.network)$degree)\n# Degine color group (I will explore this feature later).\nnetwork.D3$nodes %<>% mutate(Group = 1)\n# Define edges width. \nnetwork.D3$links$Width <- 10*E(cc.network)$width\n\nforceNetwork(\n  Links = network.D3$links, \n  Nodes = network.D3$nodes, \n  Source = 'source', \n  Target = 'target',\n  NodeID = 'name',\n  Group = 'Group', \n  opacity = 0.9,\n  Value = 'Width',\n  Nodesize = 'Degree', \n  # We input a JavaScript function.\n  linkWidth = JS(\"function(d) { return Math.sqrt(d.value); }\"), \n  fontSize = 12,\n  zoom = TRUE, \n  opacityNoHover = 1\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:28.166299Z","iopub.execute_input":"2021-10-30T15:23:28.167620Z","iopub.status.idle":"2021-10-30T15:23:28.654030Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"comm.det.obj <- cluster_louvain(\n  graph = network, \n  weights = E(network)$weight\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:28.657025Z","iopub.execute_input":"2021-10-30T15:23:28.658905Z","iopub.status.idle":"2021-10-30T15:23:28.674099Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"comm.det.obj","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:28.676787Z","iopub.execute_input":"2021-10-30T15:23:28.678130Z","iopub.status.idle":"2021-10-30T15:23:28.693829Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"V(cc.network)$membership <- membership(comm.det.obj)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:28.696661Z","iopub.execute_input":"2021-10-30T15:23:28.698007Z","iopub.status.idle":"2021-10-30T15:23:28.710413Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# We use the membership label to color the nodes.\nnetwork.D3$nodes$Group <- V(cc.network)$membership\n\nforceNetwork(\n  Links = network.D3$links, \n  Nodes = network.D3$nodes, \n  Source = 'source', \n  Target = 'target',\n  NodeID = 'name',\n  Group = 'Group', \n  opacity = 0.9,\n  Value = 'Width',\n  Nodesize = 'Degree', \n  # We input a JavaScript function.\n  linkWidth = JS(\"function(d) { return Math.sqrt(d.value); }\"), \n  fontSize = 12,\n  zoom = TRUE, \n  opacityNoHover = 1\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:23:28.713211Z","iopub.execute_input":"2021-10-30T15:23:28.714507Z","iopub.status.idle":"2021-10-30T15:23:28.770455Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}